{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script will read COCO captions annotation, split each caption\n",
    "sentence into subject phrase, verb pharse and location phrase.\n",
    "Then save them back to a new annotation json file.\n",
    "coco_splitted_captions_train2014.json\n",
    "\n",
    "Install spacy:\n",
    "pip install spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "'''\n",
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_path = '../../../../datasets/coco'\n",
    "coco_captions_train2014 = json.load(open(COCO_path + '/annotations/captions_train2014.json', 'rt'))\n",
    "\n",
    "id2image = {}\n",
    "id2captions = {}\n",
    "for img in coco_captions_train2014['images']:\n",
    "    id2image[img['id']] = img\n",
    "    id2captions[img['id']] = []\n",
    "for caption in coco_captions_train2014['annotations']:\n",
    "    id2captions[caption['image_id']] += [caption]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let perform split on this example: a red man in red shirt crying in the wood\n",
      "(['a red man in red shirt', 'crying', 'in the wood'], 'a red man in red shirt', 'crying', 'in the wood')\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    words = str(text).lower().translate(None, string.punctuation).strip().split()\n",
    "    return ' '.join(words)\n",
    "\n",
    "def split_caption(text):\n",
    "    text = normalize_text(text)\n",
    "    split_indices = [0]\n",
    "    doc = nlp(unicode(text))\n",
    "    words = text.split()\n",
    "    verb_phrase = None\n",
    "    location_phrase = None\n",
    "    if not len(words) == len(doc):\n",
    "        return [], None, None, None\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.pos_ == u'VERB' and token.tag_ != u'VBN':\n",
    "            split_indices += [i]  \n",
    "            verb_phrase = ' '.join(words[i:])\n",
    "            break\n",
    "    for i, token in reversed(list(enumerate(doc))):\n",
    "        if token.pos_ == u'ADP' and token.text not in ['of']:\n",
    "            if len(split_indices) == 2 and i <= split_indices[1]:\n",
    "                continue\n",
    "            split_indices += [i]\n",
    "            location_phrase = ' '.join(words[i:])\n",
    "            break\n",
    "    split_indices += [len(words)]\n",
    "    split_indices = np.unique(split_indices)\n",
    "    all_phrases = []\n",
    "    for i in range(len(split_indices)-1):\n",
    "        all_phrases += [' '.join(words[split_indices[i]:split_indices[i+1]])]\n",
    "    subject_phrase = all_phrases[0]\n",
    "    if len(all_phrases) == 3:\n",
    "        subject_phrase, verb_phrase, location_phrase = all_phrases\n",
    "    return all_phrases, subject_phrase, verb_phrase, location_phrase\n",
    "\n",
    "# lets do an example here\n",
    "text = 'a red man in red shirt crying in the wood'\n",
    "print 'Let perform split on this example:', text\n",
    "print split_caption(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets try on these sentences-----------------\n",
      "           A  small black sheep in a field with other larger sheep\n",
      "           A small, black sheep looks away in the grass.\n",
      "           A baby sheep stands with a group of adult sheep in a grassy meadow.\n",
      "           A herd of sheep grazing on a filed with tall green grass.\n",
      "           A black lamb stands with its family in a lush green field.\n",
      "subjects -----------------------------------\n",
      "           ['a small black sheep in a field', 'a small black sheep', 'a baby sheep', 'a herd of sheep grazing on a filed', 'a black lamb']\n",
      "verbs -----------------------------------\n",
      "           ['looks away', 'stands with a group of adult sheep', 'stands with its family']\n",
      "locations -----------------------------------\n",
      "           ['with other larger sheep', 'in the grass', 'in a grassy meadow', 'with tall green grass', 'in a lush green field']\n"
     ]
    }
   ],
   "source": [
    "print 'Lets try on these sentences-----------------'\n",
    "subjects = []\n",
    "verbs = []\n",
    "locations = []\n",
    "for caption in id2captions[id2captions.keys()[113]]:\n",
    "    print '          ', caption['caption']\n",
    "    phrases, subject, verb, location = split_caption(caption['caption'])\n",
    "    subjects += [subject]\n",
    "    verbs += [verb]\n",
    "    locations += [location]\n",
    "subjects = [i for i in subjects if i is not None]\n",
    "verbs = [i for i in verbs if i is not None]\n",
    "locations = [i for i in locations if i is not None]\n",
    "print 'subjects -----------------------------------'\n",
    "print '          ', subjects\n",
    "print 'verbs -----------------------------------'\n",
    "print '          ', verbs\n",
    "print 'locations -----------------------------------'\n",
    "print '          ', locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [1:01:17<00:00, 112.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for caption in tqdm(coco_captions_train2014['annotations']):\n",
    "    caption['phrases'], caption['subject_phrase'], caption['verb_phrase'], caption['location_phrase'] = split_caption(caption['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(coco_captions_train2014, open('coco_splitted_captions_train2014.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'image_id': 511577, u'phrases': [u'a narrow bathroom', u'with a sink shower and toilet'], u'caption': u'A narrow bathroom with a sink, shower and toilet.\\n', u'verb_phrase': None, u'subject_phrase': u'a narrow bathroom', u'location_phrase': u'with a sink shower and toilet', u'id': 27037}\n"
     ]
    }
   ],
   "source": [
    "x = json.load(open('coco_splitted_captions_train2014.json', 'rt'))\n",
    "print x['annotations'][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
